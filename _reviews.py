import requests
from bs4 import BeautifulSoup
import re
import json


#response = requests.get(url,headers=headers)
#soup = BeautifulSoup(response.text, "html.parser")

#url = ""
headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36"}

#ä½ééœ²å‹è©•åƒ¹ç¶²ç«™ :
def get_camp_name(soup):
    """ç‡Ÿåœ°åŸºæœ¬è³‡è¨Š""" 
    h1_tag =  soup.select_one("h1")
    name = h1_tag.contents[0].strip()
    return name


def get_overall_stars(soup):
    """ç‡Ÿåœ°ç²å¾—æ˜Ÿæ•¸"""
    all_stars = soup.select_one("a.icon-star-position.assessment_scroll")#å›å‚³ä¸€å€‹tagç‰©ä»¶
    # given_stars = len(all_stars.select("i.fa-star"))#å¾—åˆ°å¹¾å€‹æ˜Ÿæ˜Ÿ
    # return given_stars
    if all_stars:
        given_stars = len(all_stars.select("i.fa-star"))
        return given_stars
    return 0

#è©•åƒ¹       <h5 class="icon-font-color">
def get_review_count(soup):
    """ç²å¾—è©•è«–æ•¸"""
    review_count = soup.select_one("h5.icon-font-color")
    if review_count:
        text = review_count.text.strip()
        match = re.search(r'([\d,]+)', text)#æŠ“å‡ºç¬¬ä¸€å€‹åŒ…å«æ•¸å­—èˆ‡é€—è™Ÿçš„ç‰‡æ®µ
        if match:
            number_str = match.group(1).replace(",", "")  # ä¸è«–åƒåˆ†ä½æœ‰ç„¡é€—è™Ÿéƒ½å…ˆç§»é™¤
            return int(number_str)
    return 0

#å¦‚æœget_review_count=0 å°±ä¸æœƒæœ‰ä»¥ä¸‹ 
def get_score(soup):    
    """ç‡Ÿåœ°å„é …å¾—åˆ†"""
    scores = []
    score_blocks = soup.select("div.col-md-12.col-sm-12.col-xs-12.evaluation-padding div.text-center")
    if not score_blocks:  # å¦‚æœæ²’æœ‰è©•åˆ†å€å¡Šï¼Œè¿”å›äº”å€‹ None é¿å…å¾ŒçºŒå‡ºéŒ¯
        return [None] * 5 
    for block in score_blocks:
        star_count = len(block.select("i.fa-star"))  # è¨ˆç®—æ˜Ÿæ˜Ÿæ•¸
        scores.append(str(star_count))  # å­˜æˆå­—ä¸²æ–¹ä¾¿å¾ŒçºŒè™•ç†
    return scores #[4,5,5,4,4]

#traffic_score, bathroom_score, view_score, service_score, facility_score = get_score(soup)
# camp_scores = {
#     "äº¤é€šä¾¿åˆ©åº¦": traffic_score,
#     "è¡›æµ´æ•´æ½”åº¦": bathroom_score,
#     "æ™¯è§€æ»¿æ„åº¦": view_score,
#     "æœå‹™å“è³ª": service_score,
#     "è¨­æ–½å®Œå–„åº¦": facility_score

#é¡§å®¢è©•è«–å…§å®¹ å¦‚æœget_review_count=0 å°±ä¸æœƒæœ‰ä»¥ä¸‹
def get_customer_name(soup): 
    """è©•è«–è€…å§“å"""
    costumer_name = soup.select_one("div.col-md-12.col-sm-12.col-xs-12 > h3") 
    return re.sub(r'[\s\u200B\u200C\u200D\uFEFF]+', '', costumer_name.text) if costumer_name else None


def get_dates(soup):
    """å…¥ä½æ—¥æœŸ&è©•è«–æ—¥æœŸ"""
    all_divs = soup.select("div.col-md-12.col-sm-12.col-xs-12.font-size-16px")
    checkin_date = None
    review_date = None
    for div in all_divs:
        text = div.text.strip()
        date_match = re.search(r"\d{4}/\d{2}/\d{2}", text)  # æ‰¾ YYYY/MM/DD æ ¼å¼
        if "å…¥ä½" in text and date_match:
            checkin_date = date_match.group()
        elif "è©•åƒ¹" in text and date_match:
            review_date = date_match.group()
    return checkin_date, review_date


def get_customer_rating(soup):
    """è©•è«–è€…çµ¦äºˆçš„æ˜Ÿæ•¸""" #<div class="col-md-3 col-sm-3 col-xs-3 icon-star-padding">
    rating_div= soup.select_one("div.col-md-3.col-sm-3.col-xs-3.icon-star-padding")
    customer_rating = len(rating_div.select("i.fa-star"))
    return customer_rating


def get_customer_reviews(block):
    """è©•è«–å…§å®¹""" #è©•è«– <div class="col-md-12 col-sm-12 col-xs-12 font-size-16px con-padding-5px">æœ‰å…©å€‹ï¼Œåº•ä¸‹åˆ†åˆ¥æœ‰ 
    title_tag = block.select_one("div.title-font-size.english-break-word")
    content_tag = block.select_one("div.content-font-size.english-break-word")
        
    review_title = title_tag.text.strip()if title_tag else ""
    review_content = content_tag.text.strip()if content_tag else ""

    return review_title,review_content



def get_one_place_reviews(url):
    """ç²å¾—å–®ä¸€éœ²ç‡Ÿå ´è©•åˆ†"""
    response = requests.get(url,headers=headers)
    if response.status_code != 200:
        print(f"è«‹æ±‚å¤±æ•—ï¼Œstatus code: {response.status_code}")
    soup = BeautifulSoup(response.text, "html.parser")
    
    review_container = soup.select_one("#tab11")
    all_reviews = []
    if review_container: #å¦‚æœæœ‰è©•è«–å€
        review_blocks = review_container.select("div.row")
        for block in review_blocks:
            name = get_customer_name(block)
            checkin_date, review_date = get_dates(block)
            customer_rating = get_customer_rating(block)
            review_title, review_content = get_customer_reviews(block)
            review_data = {
                "å§“å": name,
                "å…¥ä½æ—¥æœŸ": checkin_date,
                "è©•è«–æ—¥æœŸ": review_date,
                "è©•åˆ†": customer_rating,
                "è©•è«–æ¨™é¡Œ": review_title,
                "è©•è«–å…§å®¹": review_content,    
            }
            all_reviews.append(review_data)
    
    return {
        "ç‡Ÿåœ°åç¨±": get_camp_name(soup),
        "ç‡Ÿåœ°ç¸½æ˜Ÿç­‰": get_overall_stars(soup),
        "è©•è«–ç¸½æ•¸": get_review_count(soup),
        "äº¤é€šä¾¿åˆ©åº¦": get_score(soup)[0],
        "è¡›æµ´æ•´æ½”åº¦": get_score(soup)[1],
        "æ™¯è§€æ»¿æ„åº¦": get_score(soup)[2],
        "æœå‹™å“è³ª": get_score(soup)[3],
        "è¨­æ–½å®Œå–„åº¦":get_score(soup)[4],
        "é¡§å®¢è©•è«–":all_reviews
        }

def save_to_json(data, filename):
    """å­˜å…¥ JSON æª”"""
    with open(filename, "w", encoding="utf-8") as f:
       json.dump(data, f, indent=4, ensure_ascii=False)




url = "https://www.easycamp.com.tw/store/purchase_rank/2649"
review_data = get_one_place_reviews(url)
save_to_json(review_data, "no_reviews.json")


##å…¶ä»–çš„æ”¹æ‰çš„
# å°‡ get_score(soup) çš„çµæœå­˜ç‚º scores ä¸¦è§£åŒ…ï¼Œå¯ä»¥æé«˜ç¨‹å¼ç¢¼çš„å¯è®€æ€§
# scores = get_score(soup)
# traffic, bathroom, view, service, facility = scores
       
# return {
#         "ç‡Ÿåœ°åç¨±": get_camp_name(soup),
#         "ç‡Ÿåœ°ç¸½æ˜Ÿç­‰": get_overall_stars(soup),
#         "è©•è«–ç¸½æ•¸": get_review_count(soup),
#         "äº¤é€šä¾¿åˆ©åº¦": traffic,
#         "è¡›æµ´æ•´æ½”åº¦": bathroom,
#         "æ™¯è§€æ»¿æ„åº¦": view,
#         "æœå‹™å“è³ª": service,
#         "è¨­æ–½å®Œå–„åº¦":facility,
#         "é¡§å®¢è©•è«–":all_reviews
#         }
        

###--------------------è©¦å°

# stars = get_overall_stars(soup)
# review_count = get_review_count(soup)
# print(f"â­ ç‡Ÿåœ°ç¸½æ˜Ÿç­‰ï¼š{stars} é¡†æ˜Ÿ")
# print(f"ğŸ§¾ è©•è«–ç¸½æ•¸ï¼š{review_count} å‰‡")





#2. æ‰¾å‡ºæ‰€æœ‰è©•è«–å€å¡Š
# review_container = soup.select_one("#tab11")
# all_reviews = []

# if review_container:
#     review_blocks = review_container.select("div.row")
  
#     for block in review_blocks:
#         #review_soup = BeautifulSoup(str(block), "html.parser")
#         name = get_customer_name(block)
#         checkin_date, review_date = get_dates(block)
#         customer_rating = get_customer_rating(block)
#         review_title, review_content = get_customer_reviews(block)
#         review_data = {
#             "å§“å": name,
#             "å…¥ä½æ—¥æœŸ": checkin_date,
#             "è©•è«–æ—¥æœŸ": review_date,
#             "è©•åˆ†": customer_rating,
#             "è©•è«–æ¨™é¡Œ": review_title,
#             "è©•è«–å…§å®¹": review_content,    
#         }
#         all_reviews.append(review_data)

# # 4. å°å‡ºçµæœ
# print(all_reviews)
#print(len(all_reviews))

# for i, r in enumerate(all_reviews, 1):
#     print(f"{i}. å§“å: {r['name']}, å…¥ä½: {r['checkin_date']}, è©•åƒ¹: {r['review_date']}")


#è©•è«–åˆ†é 



